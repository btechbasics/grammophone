// This file was generated by lezer-generator. You probably shouldn't edit it.
const {LRParser} = require("@lezer/lr")
exports.parser = LRParser.deserialize({
  version: 14,
  states: "#`QYQPOOOOQO'#C^'#C^O_QPO'#CgOOQO'#Ca'#CaQYQPOOOgQPO,59ROrQPO,59ROOQO-E6_-E6_OOQO'#C`'#C`OOQO'#Cb'#CbO}QPO'#C_OOQO'#Cj'#CjO!]QPO1G.mO!eQPO1G.mOOQO-E6`-E6`O!mQPO,59UOOQO7+$X7+$XOOQO1G.p1G.p",
  stateData: "!{~OXOSYOS~O[PO~O]TOaUO~O[WO_RP`RP~O[WO_RPbRP~O[WO_RX`RXbRX~O__O``O~O__Ob`O~O[WO_RP`RPbRP~O",
  goto: "!Z_PP`dkqwPPPP!PPP!TTQOSSZTURa_XXTUY_QSORVSUYTU_R^YTROSQ[TR]U",
  nodeNames: "âš  rules HeadSymbol Production ProductionSymbol",
  maxTerm: 18,
  skippedNodes: [0],
  repeatNodeCount: 2,
  tokenData: "$r~RdX^!apq!ast#Utu#m}!O$R!O!P$^![!]$c!]!^$h!c!}#m#R#S#m#T#o#m#p#q$m#y#z!a$f$g!a#BY#BZ!a$IS$I_!a$I|$JO!a$JT$JU!a$KV$KW!a&FU&FV!a~!fYX~X^!apq!a#y#z!a$f$g!a#BY#BZ!a$IS$I_!a$I|$JO!a$JT$JU!a$KV$KW!a&FU&FV!a~#ZSY~OY#UZ;'S#U;'S;=`#g<%lO#U~#jP;=`<%l#U~#rT[~tu#m!Q![#m!c!}#m#R#S#m#T#o#m~$UP!`!a$X~$^O]~~$cO`~~$hOa~~$mOb~~$rO_~",
  tokenizers: [0],
  topRules: {"rules":[0,1]},
  tokenPrec: 0
})
